{"cells":[{"cell_type":"code","source":["#Load Libraries\n# PySpark Machine Learning Library\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer, VectorAssembler, OneHotEncoderEstimator, MinMaxScaler\nfrom pyspark.sql import Row, SQLContext\nfrom pyspark.sql.functions import col, sum, when\n\nimport os\nimport sys\nfrom pyspark import SparkConf\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.types import *\nfrom pyspark.sql.session import SparkSession\n\nfrom pyspark.mllib.classification import LogisticRegressionWithSGD\nfrom pyspark.mllib.regression import LabeledPoint\nfrom numpy import array\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n# Library for confusion matrix, precision, test error\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n# Library For Area under ROC curve and Area under precision-recall curve\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics\n\n# Assign resources to the application\nsqlContext = SQLContext(sc)\n\nsc = spark.sparkContext\n\n# packages for data analysis\nimport numpy as np\nimport pandas as pd"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["#access data\nbirthDf = spark.read.options(header=\"true\",\\\n                             inferSchema=\"true\",\\\n                             nullValue=\"NA\",\\\n                             mode=\"failfast\")\\\n                            .csv(\"/FileStore/tables/lowbwt.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["#Explore data\nbirthDf.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- ID: integer (nullable = true)\n-- LOW: integer (nullable = true)\n-- AGE: integer (nullable = true)\n-- RACE: integer (nullable = true)\n-- SMOKE: integer (nullable = true)\n-- PTL: integer (nullable = true)\n-- HT: integer (nullable = true)\n-- UI: integer (nullable = true)\n-- FTV: integer (nullable = true)\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["#check missing values\nfrom pyspark.sql.functions import isnan, when, count, col\nfileDF = birthDf[['ID', 'LOW', 'AGE', 'RACE', 'SMOKE', 'PTL',\n                  'HT', 'UI', 'FTV']]\n\nfileDF.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in fileDF.columns]).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+---+----+-----+---+---+---+---+\n ID|LOW|AGE|RACE|SMOKE|PTL| HT| UI|FTV|\n+---+---+---+----+-----+---+---+---+---+\n  0|  0|  0|   0|    0|  0|  0|  0|  0|\n+---+---+---+----+-----+---+---+---+---+\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Number of patients and number of patients by birth weight category\nprint('Number of Patients: ', birthDf.count())\n\nprint('Number of patients by birth weight category: ')\nbirthDf.groupby('LOW').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of Patients:  189\nNumber of patients by birth weight category: \n+---+-----+\nLOW|count|\n+---+-----+\n  1|   59|\n  0|  130|\n+---+-----+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# From above, we can see this data is imbalanced.  For future weighting purposes, we store the imbalance percentage\n# to a variable we can use later.\n\nimbalanced = 130.0/59\n\nprint('Normal birth weight makes up {}x more of the data than low birth weight.'.format(imbalanced))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Normal birth weight makes up 2.2033898305084745x more of the data than low birth weight.\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# show the stats summary for our two continuous numeric variables\n\nprint('Summary statistics for all three continuous numeric variables: ')\nbirthDf.select(['AGE', 'PTL', 'FTV']).describe().toPandas().transpose()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>summary</th>\n      <td>count</td>\n      <td>mean</td>\n      <td>stddev</td>\n      <td>min</td>\n      <td>max</td>\n    </tr>\n    <tr>\n      <th>AGE</th>\n      <td>189</td>\n      <td>23.238095238095237</td>\n      <td>5.2986779334042655</td>\n      <td>14</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>PTL</th>\n      <td>189</td>\n      <td>0.19576719576719576</td>\n      <td>0.4933419132673032</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>FTV</th>\n      <td>189</td>\n      <td>0.7936507936507936</td>\n      <td>1.0592861429875455</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n%matplotlib inline\n\ndf_race=birthDf.crosstab('RACE', 'LOW').toPandas()\nprint('\\nCrosstabulation between birth weight category and race: ')\nprint(df_race)\n\ndf_smoke=birthDf.crosstab('SMOKE', 'LOW').toPandas()\nprint('\\nCrosstabulation between birth weight category and history of smoking while pregnant: ')\nprint(df_smoke)\n\ndf_ht=birthDf.crosstab('HT', 'LOW').toPandas()\nprint('\\nCrosstabulation between birth weight category and history of hypertension: ')\nprint(df_ht)\n\ndf_ui=birthDf.crosstab('UI', 'LOW').toPandas()\nprint('\\nCrosstabulation between birth weight category and uterine irritability: ')\nprint(df_ui)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">%matplotlib inline is not supported in Databricks.\nYou can display matplotlib figures using display(). For an example, see https://docs.databricks.com/user-guide/visualizations/matplotlib-and-ggplot.html\n\nCrosstabulation between birth weight category and race: \n  RACE_LOW   0   1\n0        2  15  11\n1        1  73  23\n2        3  42  25\n\nCrosstabulation between birth weight category and history of smoking while pregnant: \n  SMOKE_LOW   0   1\n0         1  44  30\n1         0  86  29\n\nCrosstabulation between birth weight category and history of hypertension: \n  HT_LOW    0   1\n0      1    5   7\n1      0  125  52\n\nCrosstabulation between birth weight category and uterine irritability: \n  UI_LOW    0   1\n0      1   14  14\n1      0  116  45\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Bar charts for all crosstabulation tables between birth weight category and our categorical variables\n\ndf_race.plot.bar(x=\"RACE_LOW\", legend=True, title=\"Birth weight category by mother's race\")\ndf_smoke.plot.bar(x=\"SMOKE_LOW\", legend=True, title=\"Birth weight category by mother's smoking habit while pregnant\")\ndf_ht.plot.bar(x=\"HT_LOW\", legend=True, title=\"Birth weight category by mother's history of hypertension\")\ndf_ui.plot.bar(x=\"UI_LOW\", legend=True, title=\"Birth weight category by mother's history of uterine irritability\")\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Average age by birth weight\n# Convert Age and number of physician appointments in first trimester to numeric\n\npdf=birthDf.toPandas()\npdf[\"AGE\"]=pd.to_numeric(pdf.AGE)\npdf[\"FTV\"]=pd.to_numeric(pdf.FTV)\npdf[\"PTL\"]=pd.to_numeric(pdf.PTL)\n\ndf=sqlContext.createDataFrame(pdf)\n\nprint('Average age by birth weight category:')\nPAGE=df.groupby(['LOW'])\\\n.agg({\"AGE\": \"AVG\"}).toPandas()\nprint(PAGE)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Average age by birth weight category:\n   LOW   avg(AGE)\n0    1  22.305085\n1    0  23.661538\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["#Age distribution for all mothers\n\ndf.toPandas()[\"AGE\"].plot.hist(x=\"Age\", bins=[0,5,10,15,20,25,30,35,40,45], title=\"Age distribution\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f49b011a550&gt;</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# Age distribution for mothers of children with by birth weight category\n# With sweet Maryland colors\n\ndf_age_low=df.select('AGE', 'LOW').filter(df['LOW']=='1')\npdf_age_low=df_age_low.select('AGE').toPandas()\ndf_age_high=df.select('AGE', 'LOW').filter(df['LOW']=='0')\npdf_age_high=df_age_high.select('AGE').toPandas()\nplt.hist(pdf_age_low.AGE, color='red', alpha=0.5, bins=[0,5,10,15,20,25,30,35,40,45], label='Low birth weight')\nplt.hist(pdf_age_high.AGE, color='yellow', alpha=0.5, bins=[0,5,10,15,20,25,30,35,40,45], label='Normal birth weight')\nplt.title(\"Mother's age by birth weight category\")\nplt.legend(loc='upper right')\ndisplay(plt.show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["#Average number of first trimester physician appointments by birth weight category\n\nprint('Average number of first trimester appointments by birth weight category: ')\nPFTV=df.groupby(['LOW'])\\\n.agg({\"FTV\": \"AVG\"}).toPandas()\nprint(PFTV)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Average number of first trimester appointments by birth weight category: \n   LOW  avg(FTV)\n0    1  0.694915\n1    0  0.838462\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["#First trimester appointments distribution for all mothers\ndf.toPandas()[\"FTV\"].plot.hist(x=\"First trimester appointments\", bins=[0,1,2,3,4,5,6], title=\"First trimester appointments distribution\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f49b011a550&gt;</div>"]}}],"execution_count":14},{"cell_type":"code","source":["# Age distribution for mothers of children with low birth weight\n# With sweet Virginia Tech colors / Go Hokies! (and UMUC! I love you guys too but you're covered by Maryland colors)\n\ndf_ftv_low=df.select('FTV', 'LOW').filter(df['LOW']=='1')\npdf_ftv_low=df_ftv_low.select('FTV').toPandas()\ndf_ftv_high=df.select('FTV', 'LOW').filter(df['LOW']=='0')\npdf_ftv_high=df_ftv_high.select('FTV').toPandas()\nplt.hist(pdf_ftv_low.FTV, color='maroon', alpha=0.5, bins=[0,1,2,3,4,5,6], label='Low birth weight')\nplt.hist(pdf_ftv_high.FTV, color='orange', alpha=0.5, bins=[0,1,2,3,4,5,6], label='Normal birth weight')\nplt.title('First trimester physician visits by birth weight category')\nplt.legend(loc='upper right')\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["print('Average age by birth weight category:')\nPAGE=df.groupby(['LOW'])\\\n.agg({\"PTL\": \"AVG\"}).toPandas()\nprint(PAGE)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Average age by birth weight category:\n   LOW  avg(PTL)\n0    1  0.338983\n1    0  0.130769\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["# Preterm labor distribution for all mothers\ndf.toPandas()[\"PTL\"].plot.hist(x=\"Number of preterm labors\", bins=[0,1,2,3,4], title=\"Preterm labor distribution\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f49b0143748&gt;</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# Age distribution for mothers of children with by birth weight category\n# With glorious summer colors\ndf_ptl_low=df.select('PTL', 'LOW').filter(df['LOW']=='1')\npdf_ptl_low=df_ptl_low.select('PTL').toPandas()\ndf_ptl_high=df.select('PTL', 'LOW').filter(df['LOW']=='0')\npdf_ptl_high=df_ptl_high.select('PTL').toPandas()\nplt.hist(pdf_ptl_low.PTL, color='green', alpha=0.5, bins=[0,1,2,3,4], label='Low birth weight')\nplt.hist(pdf_ptl_high.PTL, color='yellow', alpha=0.5, bins=[0,1,2,3,4], label='Normal birth weight')\nplt.title('History of preterm labor by birth weight category')\nplt.legend(loc='upper right')\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["data = sc.textFile(\"/FileStore/tables/lowbwt.csv\")\nprint (\"Total records in the data set:\", birthDf.count())\nprint (\"The first 5 rows\")\nbirthDf.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Total records in the data set: 189\nThe first 5 rows\nOut[22]: [Row(ID=85, LOW=0, AGE=19, RACE=2, SMOKE=0, PTL=0, HT=0, UI=1, FTV=0),\n Row(ID=86, LOW=0, AGE=33, RACE=3, SMOKE=0, PTL=0, HT=0, UI=0, FTV=3),\n Row(ID=87, LOW=0, AGE=20, RACE=1, SMOKE=1, PTL=0, HT=0, UI=0, FTV=1),\n Row(ID=88, LOW=0, AGE=21, RACE=1, SMOKE=1, PTL=0, HT=0, UI=1, FTV=2),\n Row(ID=89, LOW=0, AGE=18, RACE=1, SMOKE=1, PTL=0, HT=0, UI=1, FTV=0)]</div>"]}}],"execution_count":19},{"cell_type":"code","source":["# Label is the target variable LOW\n# All binary and continuous numeric variables will be converted to float and used \"as-is,\" since there is really no point to\n# one-hot encode a binary variable.  Given that, only one variable remains which cannot be considered binary or continuous\n# numeric--Race.  Since Race is the only categorical variable, we skip the whole one-hot encoding and then assembling\n# part of the pipeline by just one-hot encoding it manually in the parser.  PersonID is just there to be there\n# because we aren't really going to do anything with it at all except include it as an identifier when looking at predictions.\n# FTV and PTL are transformed via square root to semi-normalize them, as they are clearly skewed to the left in the plot above.\n\nLabeledDocument = Row(\"PersonID\", \"Age\", \"Race_1\", \"Race_2\", \"Smoke\", \"PTL\", \"sqrt_PTL\", \"HT\", \"UI\", \"FTV\", \"sqrt_FTV\", \"label\")\n\n# Define a function that parses each row in a CSV file and returns an object of type LabeledDocument\n\ndef parseDocument(line):\n    values = [str(x) for x in line.split(',')]\n    race = int(values[3])\n    race_1=0.0\n    race_2=0.0\n    if race==1:\n        race_1=1.0\n    elif race==2:\n        race_2=1.0\n    pid = str(values[0])\n    age = float(values[2])\n    smoke = float(values[4])\n    ptl = float(values[5])\n    sqrt_ptl = float(np.sqrt(ptl))\n    ht = float(values[6])\n    ui = float(values[7])\n    ftv = float(values[8])\n    sqrt_ftv = float(np.sqrt(ftv))\n    labels = float(values[1])\n    \n    return LabeledDocument(pid, age, race_1, race_2, smoke, ptl, sqrt_ptl, ht, ui, ftv, sqrt_ftv, labels)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["#Parse and Load the data into a dataframe. The code calls the parsing function defined above\n\ndocuments=data.filter(lambda s: \"LOW\" not in s).map(parseDocument)\nBirthWeightData = documents.toDF()\nprint (\"Number of records: \" + str(BirthWeightData.count()))\nprint ( \"First 5 records: \")\nBirthWeightData.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of records: 189\nFirst 5 records: \nOut[24]: [Row(PersonID=&#39;85&#39;, Age=19.0, Race_1=0.0, Race_2=1.0, Smoke=0.0, PTL=0.0, sqrt_PTL=0.0, HT=0.0, UI=1.0, FTV=0.0, sqrt_FTV=0.0, label=0.0),\n Row(PersonID=&#39;86&#39;, Age=33.0, Race_1=0.0, Race_2=0.0, Smoke=0.0, PTL=0.0, sqrt_PTL=0.0, HT=0.0, UI=0.0, FTV=3.0, sqrt_FTV=1.7320508075688772, label=0.0),\n Row(PersonID=&#39;87&#39;, Age=20.0, Race_1=1.0, Race_2=0.0, Smoke=1.0, PTL=0.0, sqrt_PTL=0.0, HT=0.0, UI=0.0, FTV=1.0, sqrt_FTV=1.0, label=0.0),\n Row(PersonID=&#39;88&#39;, Age=21.0, Race_1=1.0, Race_2=0.0, Smoke=1.0, PTL=0.0, sqrt_PTL=0.0, HT=0.0, UI=1.0, FTV=2.0, sqrt_FTV=1.4142135623730951, label=0.0),\n Row(PersonID=&#39;89&#39;, Age=18.0, Race_1=1.0, Race_2=0.0, Smoke=1.0, PTL=0.0, sqrt_PTL=0.0, HT=0.0, UI=1.0, FTV=0.0, sqrt_FTV=0.0, label=0.0)]</div>"]}}],"execution_count":21},{"cell_type":"code","source":["# Divide the data into training and test set with proportions 80/20\n# We will not use randomSplit used in class because it does not produce\n# training and testing sets stratified by our target variable ('label').\n# Since this dataset is exceedingly small (ironically, since we're using SparkML),\n# it is important to make sure our test/train split is stratified so we have \"enough\"\n# of each label to train and test on.\n\nrandom_seed = 1988\ntrain = BirthWeightData.sampleBy(\"label\", fractions={0: 0.8, 1: 0.8}, seed=random_seed)\ntest = BirthWeightData.subtract(train)\n\nprint(\"Number of records in the training set: \" + str(train.count()))\nprint(\"Number of records in the test set: \" + str(test.count()))\nprint(\"\\nProportion of training set to total dataset: \" + str(train.count()/(test.count()+train.count()))) \n# Output first 20 records in the training set\n\nprint (\"\\nFirst 5 records in the training set: \")\ntrain.show(5)\n\nprint (\"\\nFirst 5 records in the testing set: \")\ntest.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of records in the training set: 147\nNumber of records in the test set: 42\n\nProportion of training set to total dataset: 0.7777777777777778\n\nFirst 5 records in the training set: \n+--------+----+------+------+-----+---+--------+---+---+---+------------------+-----+\nPersonID| Age|Race_1|Race_2|Smoke|PTL|sqrt_PTL| HT| UI|FTV|          sqrt_FTV|label|\n+--------+----+------+------+-----+---+--------+---+---+---+------------------+-----+\n      85|19.0|   0.0|   1.0|  0.0|0.0|     0.0|0.0|1.0|0.0|               0.0|  0.0|\n      86|33.0|   0.0|   0.0|  0.0|0.0|     0.0|0.0|0.0|3.0|1.7320508075688772|  0.0|\n      87|20.0|   1.0|   0.0|  1.0|0.0|     0.0|0.0|0.0|1.0|               1.0|  0.0|\n      88|21.0|   1.0|   0.0|  1.0|0.0|     0.0|0.0|1.0|2.0|1.4142135623730951|  0.0|\n      89|18.0|   1.0|   0.0|  1.0|0.0|     0.0|0.0|1.0|0.0|               0.0|  0.0|\n+--------+----+------+------+-----+---+--------+---+---+---+------------------+-----+\nonly showing top 5 rows\n\n\nFirst 5 records in the testing set: \n+--------+----+------+------+-----+---+--------+---+---+---+------------------+-----+\nPersonID| Age|Race_1|Race_2|Smoke|PTL|sqrt_PTL| HT| UI|FTV|          sqrt_FTV|label|\n+--------+----+------+------+-----+---+--------+---+---+---+------------------+-----+\n     132|18.0|   1.0|   0.0|  1.0|0.0|     0.0|0.0|1.0|0.0|               0.0|  0.0|\n     172|20.0|   0.0|   1.0|  1.0|0.0|     0.0|0.0|0.0|0.0|               0.0|  0.0|\n      56|31.0|   1.0|   0.0|  1.0|1.0|     1.0|0.0|0.0|1.0|               1.0|  1.0|\n     202|25.0|   0.0|   1.0|  0.0|0.0|     0.0|1.0|0.0|0.0|               0.0|  0.0|\n      27|20.0|   1.0|   0.0|  1.0|0.0|     0.0|0.0|0.0|2.0|1.4142135623730951|  1.0|\n+--------+----+------+------+-----+---+--------+---+---+---+------------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["# set up Logistic Regression using SparkML pipeline\n\nassembler = VectorAssembler(inputCols=[\"Age\", \"Smoke\", \"Race_1\", \"Race_2\", \"sqrt_PTL\", \"HT\", \"UI\", \"sqrt_FTV\"], outputCol=\"features\")\nlr = LogisticRegression(maxIter=100, regParam=0.01)\npipeline = Pipeline(stages=[assembler, lr])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["# train the logistic regression model\nmodel = pipeline.fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["# Make predictions for test data and print columns of interest\nprediction = model.transform(test)\nselected = prediction.select(\"PersonID\", \"label\", \"prediction\", \"probability\")\nfor row in selected.collect():\n    print (row)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Row(PersonID=&#39;132&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.6024, 0.3976]))\nRow(PersonID=&#39;172&#39;, label=0.0, prediction=1.0, probability=DenseVector([0.4933, 0.5067]))\nRow(PersonID=&#39;56&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.6585, 0.3415]))\nRow(PersonID=&#39;202&#39;, label=0.0, prediction=1.0, probability=DenseVector([0.3324, 0.6676]))\nRow(PersonID=&#39;27&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.7396, 0.2604]))\nRow(PersonID=&#39;82&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.6389, 0.3611]))\nRow(PersonID=&#39;167&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.6882, 0.3118]))\nRow(PersonID=&#39;221&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8979, 0.1021]))\nRow(PersonID=&#39;136&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8906, 0.1094]))\nRow(PersonID=&#39;31&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.6347, 0.3653]))\nRow(PersonID=&#39;140&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.7782, 0.2218]))\nRow(PersonID=&#39;57&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.8114, 0.1886]))\nRow(PersonID=&#39;217&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8587, 0.1413]))\nRow(PersonID=&#39;37&#39;, label=1.0, prediction=1.0, probability=DenseVector([0.1576, 0.8424]))\nRow(PersonID=&#39;155&#39;, label=0.0, prediction=1.0, probability=DenseVector([0.3229, 0.6771]))\nRow(PersonID=&#39;78&#39;, label=1.0, prediction=1.0, probability=DenseVector([0.2015, 0.7985]))\nRow(PersonID=&#39;220&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8807, 0.1193]))\nRow(PersonID=&#39;10&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.8757, 0.1243]))\nRow(PersonID=&#39;106&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8758, 0.1242]))\nRow(PersonID=&#39;145&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8647, 0.1353]))\nRow(PersonID=&#39;44&#39;, label=1.0, prediction=1.0, probability=DenseVector([0.4522, 0.5478]))\nRow(PersonID=&#39;60&#39;, label=1.0, prediction=1.0, probability=DenseVector([0.4933, 0.5067]))\nRow(PersonID=&#39;118&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.5291, 0.4709]))\nRow(PersonID=&#39;22&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.8836, 0.1164]))\nRow(PersonID=&#39;187&#39;, label=0.0, prediction=1.0, probability=DenseVector([0.3149, 0.6851]))\nRow(PersonID=&#39;224&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.7356, 0.2644]))\nRow(PersonID=&#39;63&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.7883, 0.2117]))\nRow(PersonID=&#39;169&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8994, 0.1006]))\nRow(PersonID=&#39;213&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.7993, 0.2007]))\nRow(PersonID=&#39;148&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.701, 0.299]))\nRow(PersonID=&#39;77&#39;, label=1.0, prediction=0.0, probability=DenseVector([0.8269, 0.1731]))\nRow(PersonID=&#39;128&#39;, label=0.0, prediction=1.0, probability=DenseVector([0.4984, 0.5016]))\nRow(PersonID=&#39;156&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.7917, 0.2083]))\nRow(PersonID=&#39;205&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.7088, 0.2912]))\nRow(PersonID=&#39;141&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8601, 0.1399]))\nRow(PersonID=&#39;162&#39;, label=0.0, prediction=1.0, probability=DenseVector([0.3736, 0.6264]))\nRow(PersonID=&#39;175&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.9411, 0.0589]))\nRow(PersonID=&#39;101&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.7204, 0.2796]))\nRow(PersonID=&#39;215&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8979, 0.1021]))\nRow(PersonID=&#39;139&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.7883, 0.2117]))\nRow(PersonID=&#39;102&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.5821, 0.4179]))\nRow(PersonID=&#39;196&#39;, label=0.0, prediction=0.0, probability=DenseVector([0.8922, 0.1078]))\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["#Evaluate the Model (Logistic Regression)\n#We evaluate the model on the training set and test set. The purpose is to measure the model's predictive accuracy, including the accuracy for new data.\n\ndef full_metrics(model, data, curve_metrics=False):\n    pred_m=model.transform(data).select(\"prediction\", \"label\")\n    eval_m=MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n    accuracy_m=eval_m.evaluate(pred_m)\n    predictionAndLabels_m=pred_m.rdd\n    metrics_m=MulticlassMetrics(predictionAndLabels_m)\n    precision_m=metrics_m.precision(1.0)\n    recall_m=metrics_m.recall(1.0)\n    f1Measure_m = metrics_m.fMeasure(1.0, 1.0)\n    print (\"Accuracy = %s\" %accuracy_m)\n    print (\"Error = %s\" % (1-accuracy_m))\n    print (\"Precision = %s\" %precision_m)\n    print (\"Recall = %s\" %recall_m)\n    print (\"F1 Measure = %s\" % f1Measure_m)\n    \n    if curve_metrics:\n        bin_m=BinaryClassificationMetrics(predictionAndLabels_m)\n        print(\"Area under PR = %s\" % bin_m.areaUnderPR)\n        print(\"Area under ROC = %s\" % bin_m.areaUnderROC)\n\ndef pipe_to_metrics(model, train, test, curve_metrics=False, graph_ROC=False, model_trained=False):\n    if not model_trained:\n        model = model.fit(train)\n    \n    prediction = model.transform(train)\n    print(\"Training confusion matrix: \")\n    prediction.crosstab('label', 'prediction').show()\n    \n    prediction = model.transform(test)\n    print(\"\\nTest confusion matrix: \")\n    prediction.crosstab('label', 'prediction').show()\n    \n    print (\"\\nModel evaluation for the train data: \")\n    full_metrics(model, train, curve_metrics=curve_metrics)\n    print (\"\\nModel evaluation for the test data: \")\n    full_metrics(model, test, curve_metrics=curve_metrics)\n    \n    if graph_ROC:\n        ROC=model.stages[-1].summary.roc\n        df=ROC.toPandas()\n        df.plot(x='FPR', y='TPR', label=\"ROC\", legend=False)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["pipe_to_metrics(model, train, test, curve_metrics=True, graph_ROC=True, model_trained=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 30| 16|\n             0.0| 93|  8|\n+----------------+---+---+\n\n\nTest confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0|  9|  4|\n             0.0| 23|  6|\n+----------------+---+---+\n\n\nModel evaluation for the train data: \nAccuracy = 0.7414965986394558\nError = 0.25850340136054417\nPrecision = 0.6666666666666666\nRecall = 0.34782608695652173\nF1 Measure = 0.4571428571428571\nArea under PR = 0.5513161786453712\nArea under ROC = 0.6343090830822213\n\nModel evaluation for the test data: \nAccuracy = 0.6428571428571429\nError = 0.3571428571428571\nPrecision = 0.4\nRecall = 0.3076923076923077\nF1 Measure = 0.34782608695652173\nArea under PR = 0.3686813186813187\nArea under ROC = 0.5503978779840849\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["#Building a Decision Tree Model\nfrom pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(labelCol='label')\npipeline_dt = Pipeline(stages=[assembler, dt])\npipe_to_metrics(pipeline_dt, train, test, curve_metrics=False, graph_ROC=False, model_trained=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 25| 21|\n             0.0| 99|  2|\n+----------------+---+---+\n\n\nTest confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 10|  3|\n             0.0| 25|  4|\n+----------------+---+---+\n\n\nModel evaluation for the train data: \nAccuracy = 0.8163265306122449\nError = 0.18367346938775508\nPrecision = 0.9130434782608695\nRecall = 0.45652173913043476\nF1 Measure = 0.608695652173913\n\nModel evaluation for the test data: \nAccuracy = 0.6666666666666666\nError = 0.33333333333333337\nPrecision = 0.42857142857142855\nRecall = 0.23076923076923078\nF1 Measure = 0.3\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["#Building a Random Forest Model\n\nfrom pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(labelCol='label', numTrees=100)\npipeline_rf = Pipeline(stages=[assembler, rf])\npipe_to_metrics(pipeline_rf, train, test, curve_metrics=False, graph_ROC=False, model_trained=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 21| 25|\n             0.0| 99|  2|\n+----------------+---+---+\n\n\nTest confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 11|  2|\n             0.0| 24|  5|\n+----------------+---+---+\n\n\nModel evaluation for the train data: \nAccuracy = 0.8435374149659864\nError = 0.15646258503401356\nPrecision = 0.9259259259259259\nRecall = 0.5434782608695652\nF1 Measure = 0.6849315068493151\n\nModel evaluation for the test data: \nAccuracy = 0.6190476190476191\nError = 0.38095238095238093\nPrecision = 0.2857142857142857\nRecall = 0.15384615384615385\nF1 Measure = 0.2\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["#Building a Gradient Boosted Decision Tree Model\n\nfrom pyspark.ml.classification import GBTClassifier\n\ngb = GBTClassifier(labelCol='label', maxIter=50)\npipeline_gb = Pipeline(stages=[assembler, gb])\npipe_to_metrics(pipeline_gb, train, test, curve_metrics=False, graph_ROC=False, model_trained=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0|  9| 37|\n             0.0|100|  1|\n+----------------+---+---+\n\n\nTest confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 10|  3|\n             0.0| 23|  6|\n+----------------+---+---+\n\n\nModel evaluation for the train data: \nAccuracy = 0.9319727891156463\nError = 0.0680272108843537\nPrecision = 0.9736842105263158\nRecall = 0.8043478260869565\nF1 Measure = 0.8809523809523809\n\nModel evaluation for the test data: \nAccuracy = 0.6190476190476191\nError = 0.38095238095238093\nPrecision = 0.3333333333333333\nRecall = 0.23076923076923078\nF1 Measure = 0.27272727272727276\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["#Building a Perceptron\n\nfrom pyspark.ml.classification import MultilayerPerceptronClassifier\n\nscaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\nmp = MultilayerPerceptronClassifier(featuresCol=scaler.getOutputCol(), maxIter=100, layers=[8,8,2], blockSize=1, seed=random_seed)\npipeline_mp = Pipeline(stages=[assembler, scaler, mp])\npipe_to_metrics(pipeline_mp, train, test, curve_metrics=False, graph_ROC=False, model_trained=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 18| 28|\n             0.0|100|  1|\n+----------------+---+---+\n\n\nTest confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 10|  3|\n             0.0| 24|  5|\n+----------------+---+---+\n\n\nModel evaluation for the train data: \nAccuracy = 0.8707482993197279\nError = 0.12925170068027214\nPrecision = 0.9655172413793104\nRecall = 0.6086956521739131\nF1 Measure = 0.7466666666666666\n\nModel evaluation for the test data: \nAccuracy = 0.6428571428571429\nError = 0.3571428571428571\nPrecision = 0.375\nRecall = 0.23076923076923078\nF1 Measure = 0.2857142857142857\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["\n# #Building a Logistic Regression Model with Weighted Cost Function\n# After the whirlwind of classifiers we just built and evaluated, we arere going to bring it back to logistic regression because, well, this assignment is about building a classifier with logistic regression in Spark. A big issue we have with this data is that it is imbalanced and the logistic regression model built previously was decently accurate for the majority case but absolutely horrible (worse than random chance) at the minority case. We create a new weighted column to feed this logistic regression model to see if we can increase the accuracy and precision (recall may go down because of the weighting).\n\ntrain=train.withColumn(\"classWeights\", when(train.label == 1, imbalanced).otherwise(1))\nwlr = LogisticRegression(maxIter=100, regParam=0.01, weightCol=\"classWeights\")\npipeline_wlr = Pipeline(stages=[assembler, wlr])\npipe_to_metrics(pipeline_wlr, train, test, curve_metrics=False, graph_ROC=False, model_trained=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0| 15| 31|\n             0.0| 71| 30|\n+----------------+---+---+\n\n\nTest confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0|  6|  7|\n             0.0| 18| 11|\n+----------------+---+---+\n\n\nModel evaluation for the train data: \nAccuracy = 0.6938775510204082\nError = 0.30612244897959184\nPrecision = 0.5081967213114754\nRecall = 0.6739130434782609\nF1 Measure = 0.5794392523364487\n\nModel evaluation for the test data: \nAccuracy = 0.5952380952380952\nError = 0.40476190476190477\nPrecision = 0.3888888888888889\nRecall = 0.5384615384615384\nF1 Measure = 0.45161290322580644\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["# Tuning the Logistic Regression Model\n# The last LogReg model was probably the best overall performer with the highest F1-score on the test set. With this current problem, however, we really want to predict low birth rate better than normal birth weight--which is an issue, because we have much less data on low birth rate in our already super tiny dataset. To try to get around this, we will split the data into a train/test/val split and use the validation set to tune a weight multiplier.\n\nrandom_seed = 123\ntrain = BirthWeightData.sampleBy(\"label\", fractions={0: 0.7, 1: 0.7}, seed=random_seed)\nother = BirthWeightData.subtract(train)\ntest = other.sampleBy(\"label\", fractions={0:0.6, 1:0.6}, seed=random_seed+1)\nval = other.subtract(test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["def eval_model(model, data):\n    pred_m=model.transform(data).select(\"prediction\", \"label\")\n    predictionAndLabels_m=pred_m.rdd\n    metrics_m=MulticlassMetrics(predictionAndLabels_m)\n    return metrics_m.precision(1.0), metrics_m.recall(1.0), metrics_m.fMeasure(1.0, 1.0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["# This cell trains multiple models for different weights and creates a list of their metrics so they can be graphed and\n# compared to determine the best weighting for our purposes\n\nm_range=[]\nm_precision=[]\nm_recall=[]\nm_f1 = []\n\nfor index in range(5, 40):\n    multiplier = 0.2*index\n    train=train.withColumn(\"classWeights\", when(train.label == 1, multiplier).otherwise(1))\n    wlr = LogisticRegression(maxIter=100, regParam=0.01, weightCol=\"classWeights\")\n    pipeline_wlr = Pipeline(stages=[assembler, wlr])\n    model = pipeline_wlr.fit(train)\n    p, r, f = eval_model(model, val)\n    m_range.append(multiplier)\n    m_precision.append(p)\n    m_recall.append(r)\n    m_f1.append(f)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["plt.plot(m_range, m_precision, color='red', linestyle='-', marker='o')\nplt.plot(m_range, m_recall, color='orange', linestyle='-', marker='o')\nplt.plot(m_range, m_f1, color='blue', linestyle='-', marker='o')\nplt.xlabel('Weight multiplier')\nplt.ylabel('Metrics')\nplt.title('Metrics by weight multiplier')\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["# Clearly, we get the \"best-ish\" (but still not awesome) results with a multiplier greater than or equal to 6.2\n\n# a weight multiplier of 6.4 is used instead of 6.2 because it is a more stable position than 6.2, which\n# is at the tipping point between a huge increase and a plateau.\n\nbest_multiplier = 6.4\ntrain=train.withColumn(\"classWeights\", when(train.label == 1, best_multiplier).otherwise(1))\nwlr = LogisticRegression(maxIter=100, regParam=0.01, weightCol=\"classWeights\")\npipeline_wlr = Pipeline(stages=[assembler, wlr])\npipe_to_metrics(pipeline_wlr, train, test, curve_metrics=True, graph_ROC=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0|  2| 38|\n             0.0| 33| 56|\n+----------------+---+---+\n\n\nTest confusion matrix: \n+----------------+---+---+\nlabel_prediction|0.0|1.0|\n+----------------+---+---+\n             1.0|  1| 12|\n             0.0|  6| 26|\n+----------------+---+---+\n\n\nModel evaluation for the train data: \nAccuracy = 0.5503875968992248\nError = 0.4496124031007752\nPrecision = 0.40425531914893614\nRecall = 0.95\nF1 Measure = 0.5671641791044776\nArea under PR = 0.4019008741547089\nArea under ROC = 0.6603932584269663\n\nModel evaluation for the test data: \nAccuracy = 0.4\nError = 0.6\nPrecision = 0.3157894736842105\nRecall = 0.9230769230769231\nF1 Measure = 0.47058823529411764\nArea under PR = 0.3147548358074673\nArea under ROC = 0.5552884615384616\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["# This last model with weight multiplier of 6.4 is definitely not perfect, but it's the best so far for our purposes. When it comes to predicting whether a child will be born with a low birth weight or not, it is more important to predict low birth weight when their is low birth weight than it is to predict normal birth weight when the child has normal birth weight. If the model predicts low birth weight and the child is born with a normal birth weight then it's really a \"no harm, no foul\" situation. It's better to prepare for the worst and hope for the best than to be underprepared when a child is born with a low birth weight. With this last model, if it predicts low birth weight then there is a 92% chance (11/12 on the test set) that the child will have a low birth weight--so a 1 indicates we should take necessary precautions. Granted, with a 1 predicted there is still only a 32% chance that the child actually comes out with a low birth weight, so there will be a lot of situations where additional precautions are unnecessary--but that is a much better situation then not being prepared for a low birth weight when it occurs."],"metadata":{},"outputs":[],"execution_count":38}],"metadata":{"name":"BDA_Logistic Regression_Low Birth Weight Prediction","notebookId":2909490446020177},"nbformat":4,"nbformat_minor":0}
